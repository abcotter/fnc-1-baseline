{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec49290e",
   "metadata": {
    "id": "ec49290e",
    "outputId": "6fcfef25-5268-4a9f-b9a2-93974009cbef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer,BertForSequenceClassification, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6294711",
   "metadata": {
    "id": "b6294711"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a2de96",
   "metadata": {
    "id": "a2a2de96"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ad1bca",
   "metadata": {
    "id": "f0ad1bca"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0fa57b",
   "metadata": {
    "id": "aa0fa57b",
    "outputId": "bff19f0e-3470-4653-d080-bc79e10e0a38"
   },
   "outputs": [],
   "source": [
    "train_stances = '../fnc-1/train_stances.csv'\n",
    "train_bodies = '../fnc-1/train_bodies.csv'\n",
    "\n",
    "stances_headlines =  pd.read_csv(train_stances)[:150]\n",
    "bodies = pd.read_csv(train_bodies)\n",
    "stances_bodies = stances_headlines.merge(bodies,on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429dc8d7",
   "metadata": {
    "id": "429dc8d7",
    "outputId": "5d8513d9-540f-4fc0-d966-a60f65cb790e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stances_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3139de65",
   "metadata": {
    "id": "3139de65"
   },
   "outputs": [],
   "source": [
    "class StancesDataset(Dataset):\n",
    "    def __init__(self, headlines, bodies, stances, tokenizer, max_len):\n",
    "        self.headlines = headlines\n",
    "        self.bodies = bodies\n",
    "        self.stances = stances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.categories = {\"unrelated\": 0, \"agree\": 1, \"discuss\": 2, \"disagree\": 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        headline = self.headlines[idx]\n",
    "        body = self.bodies[idx]\n",
    "        stance = self.categories[self.stances[idx]]\n",
    "        stanceVec = [0,0,0,0]\n",
    "        stanceVec[stance] = 1\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            headline,\n",
    "            body,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"onehotlabels\": torch.tensor(stanceVec, dtype=torch.float),\n",
    "            \"labels\": torch.tensor([stance], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e3e83",
   "metadata": {
    "id": "565e3e83"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8f2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = BertConfig()\n",
    "model = BertForSequenceClassification(config = configuration)\n",
    "model = model.from_pretrained(PRE_TRAINED_MODEL_NAME, problem_type=\"multi_label_classification\", num_labels = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a86309",
   "metadata": {
    "id": "27a86309"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea61ef95",
   "metadata": {
    "id": "ea61ef95"
   },
   "outputs": [],
   "source": [
    "def train(batch_size, data, model, loss_fn, num_samples, optimizer, device='cpu'):\n",
    "    model = model.train()\n",
    "    model.to(device)\n",
    "    num_correct_predictions = 0\n",
    "    num_samples = len(data)\n",
    "    training_loss = []\n",
    "\n",
    "    batch_oldtime = time.time()\n",
    "    for i, input_data in enumerate(data):\n",
    "        batch_newtime = time.time()\n",
    "        batch_oldtime = batch_newtime\n",
    "        \n",
    "        input_ids = input_data['input_ids'].to(device)\n",
    "        attention_mask = input_data['attention_mask'].to(device)\n",
    "        token_type_ids = input_data['token_type_ids'].to(device)\n",
    "        onehotlabels = input_data['onehotlabels'].to(device).squeeze()\n",
    "        labels = input_data['labels'].to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, attention_mask, token_type_ids, labels=onehotlabels)\n",
    "        preds = output.logits\n",
    "        num_correct_predictions += torch.sum(torch.argmax(preds, dim=1) == labels)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.item())\n",
    "    return num_correct_predictions.item()/num_samples, np.mean(training_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b210470",
   "metadata": {
    "id": "3b210470"
   },
   "outputs": [],
   "source": [
    "def validate(model, data, loss_fn, num_samples, device='cpu'):\n",
    "    model = model.eval()\n",
    "    validation_losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for i, input_data in enumerate(data):\n",
    "            input_ids = input_data[\"input_ids\"].to(device)\n",
    "            attention_mask = input_data[\"attention_mask\"].to(device)\n",
    "            token_type_ids = input_data['token_type_ids'].to(device)\n",
    "            onehotlabels = input_data['onehotlabels'].to(device).squeeze()\n",
    "            labels = input_data['labels'].to(device).squeeze()\n",
    "            output = model(input_ids, attention_mask, token_type_ids, labels=onehotlabels)\n",
    "            preds=output.logits\n",
    "            loss = output.loss\n",
    "\n",
    "            correct_predictions += torch.sum(torch.argmax(preds, dim=1) == labels)\n",
    "            validation_losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.item() /num_samples, np.mean(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfd7744",
   "metadata": {
    "id": "3bfd7744"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = StancesDataset(df['Headline'].to_numpy(),\n",
    "                        df['articleBody'].to_numpy(),\n",
    "                        df['Stance'].to_numpy(),\n",
    "                        tokenizer,\n",
    "                        max_len)\n",
    "\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size\n",
    "  )\n",
    "\n",
    "df_train, df_test = train_test_split(stances_bodies, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "train_dataloader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_dataloader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_dataloader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11984577",
   "metadata": {
    "id": "11984577",
    "outputId": "116f9740-27a4-4d4a-f6f3-e38410a97c4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abicotter/opt/anaconda3/envs/msci598/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/abicotter/opt/anaconda3/envs/msci598/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time at start of epoch 0 is 0.0002071857452392578s\n",
      "Training accuracy at epoch 0 is 19.4\n",
      "Mean training loss at epoch 0 is 0.5931237578392029\n",
      "Validaton accuracy at epoch 0 is 0.7142857142857143\n",
      "Mean validation loss at epoch 0 is 0.4987427592277527\n",
      "Elapsed time at start of epoch 1 is 81.22528791427612s\n",
      "Training accuracy at epoch 1 is 21.8\n",
      "Mean training loss at epoch 1 is 0.4593853294849396\n",
      "Validaton accuracy at epoch 1 is 0.7142857142857143\n",
      "Mean validation loss at epoch 1 is 0.37733712792396545\n",
      "Elapsed time at start of epoch 2 is 81.04011487960815s\n",
      "Training accuracy at epoch 2 is 22.6\n",
      "Mean training loss at epoch 2 is 0.3573737323284149\n",
      "Validaton accuracy at epoch 2 is 0.7142857142857143\n",
      "Mean validation loss at epoch 2 is 0.2969524562358856\n",
      "Elapsed time at start of epoch 3 is 79.35876202583313s\n",
      "Training accuracy at epoch 3 is 22.8\n",
      "Mean training loss at epoch 3 is 0.27605676352977754\n",
      "Validaton accuracy at epoch 3 is 0.7142857142857143\n",
      "Mean validation loss at epoch 3 is 0.2602374255657196\n",
      "Elapsed time at start of epoch 4 is 81.47924304008484s\n",
      "Training accuracy at epoch 4 is 23.6\n",
      "Mean training loss at epoch 4 is 0.22850883901119232\n",
      "Validaton accuracy at epoch 4 is 0.7142857142857143\n",
      "Mean validation loss at epoch 4 is 0.23124635219573975\n",
      "Elapsed time at start of epoch 5 is 83.48370099067688s\n",
      "Training accuracy at epoch 5 is 24.4\n",
      "Mean training loss at epoch 5 is 0.19315895438194275\n",
      "Validaton accuracy at epoch 5 is 0.8571428571428571\n",
      "Mean validation loss at epoch 5 is 0.21492452919483185\n",
      "Elapsed time at start of epoch 6 is 82.31193804740906s\n",
      "Training accuracy at epoch 6 is 24.4\n",
      "Mean training loss at epoch 6 is 0.1757742792367935\n",
      "Validaton accuracy at epoch 6 is 0.8571428571428571\n",
      "Mean validation loss at epoch 6 is 0.204797625541687\n",
      "Elapsed time at start of epoch 7 is 79.53302025794983s\n",
      "Training accuracy at epoch 7 is 24.6\n",
      "Mean training loss at epoch 7 is 0.1571911931037903\n",
      "Validaton accuracy at epoch 7 is 0.8571428571428571\n",
      "Mean validation loss at epoch 7 is 0.204020693898201\n",
      "Elapsed time at start of epoch 8 is 80.40234279632568s\n",
      "Training accuracy at epoch 8 is 25.6\n",
      "Mean training loss at epoch 8 is 0.1419036567211151\n",
      "Validaton accuracy at epoch 8 is 0.8571428571428571\n",
      "Mean validation loss at epoch 8 is 0.19779346883296967\n",
      "Elapsed time at start of epoch 9 is 80.14616394042969s\n",
      "Training accuracy at epoch 9 is 25.4\n",
      "Mean training loss at epoch 9 is 0.1308442771434784\n",
      "Validaton accuracy at epoch 9 is 0.7142857142857143\n",
      "Mean validation loss at epoch 9 is 0.19651281833648682\n",
      "Elapsed time at start of epoch 10 is 87.22420310974121s\n",
      "Training accuracy at epoch 10 is 26.0\n",
      "Mean training loss at epoch 10 is 0.12242226153612137\n",
      "Validaton accuracy at epoch 10 is 0.7142857142857143\n",
      "Mean validation loss at epoch 10 is 0.19304387271404266\n",
      "Elapsed time at start of epoch 11 is 88.76703596115112s\n",
      "Training accuracy at epoch 11 is 26.4\n",
      "Mean training loss at epoch 11 is 0.10950682014226913\n",
      "Validaton accuracy at epoch 11 is 0.7142857142857143\n",
      "Mean validation loss at epoch 11 is 0.19817900657653809\n",
      "Elapsed time at start of epoch 12 is 87.87307786941528s\n",
      "Training accuracy at epoch 12 is 26.8\n",
      "Mean training loss at epoch 12 is 0.09525087028741837\n",
      "Validaton accuracy at epoch 12 is 0.7142857142857143\n",
      "Mean validation loss at epoch 12 is 0.1998441219329834\n",
      "Elapsed time at start of epoch 13 is 89.00840616226196s\n",
      "Training accuracy at epoch 13 is 26.8\n",
      "Mean training loss at epoch 13 is 0.08514600843191147\n",
      "Validaton accuracy at epoch 13 is 0.7142857142857143\n",
      "Mean validation loss at epoch 13 is 0.21210913360118866\n",
      "Elapsed time at start of epoch 14 is 87.08935308456421s\n",
      "Training accuracy at epoch 14 is 26.8\n",
      "Mean training loss at epoch 14 is 0.07716855332255364\n",
      "Validaton accuracy at epoch 14 is 0.7142857142857143\n",
      "Mean validation loss at epoch 14 is 0.2119801938533783\n",
      "Elapsed time at start of epoch 15 is 86.37292504310608s\n",
      "Training accuracy at epoch 15 is 27.0\n",
      "Mean training loss at epoch 15 is 0.06839473694562911\n",
      "Validaton accuracy at epoch 15 is 0.7142857142857143\n",
      "Mean validation loss at epoch 15 is 0.23734520375728607\n",
      "Elapsed time at start of epoch 16 is 87.14211511611938s\n",
      "Training accuracy at epoch 16 is 26.8\n",
      "Mean training loss at epoch 16 is 0.0625313401222229\n",
      "Validaton accuracy at epoch 16 is 0.7142857142857143\n",
      "Mean validation loss at epoch 16 is 0.22757959365844727\n",
      "Elapsed time at start of epoch 17 is 82.25834393501282s\n",
      "Training accuracy at epoch 17 is 27.0\n",
      "Mean training loss at epoch 17 is 0.05768352672457695\n",
      "Validaton accuracy at epoch 17 is 0.7142857142857143\n",
      "Mean validation loss at epoch 17 is 0.25454118847846985\n",
      "Elapsed time at start of epoch 18 is 88.14797163009644s\n",
      "Training accuracy at epoch 18 is 27.0\n",
      "Mean training loss at epoch 18 is 0.051516254991292955\n",
      "Validaton accuracy at epoch 18 is 0.7142857142857143\n",
      "Mean validation loss at epoch 18 is 0.2467106133699417\n",
      "Elapsed time at start of epoch 19 is 87.01400709152222s\n",
      "Training accuracy at epoch 19 is 27.0\n",
      "Mean training loss at epoch 19 is 0.04826431050896644\n",
      "Validaton accuracy at epoch 19 is 0.7142857142857143\n",
      "Mean validation loss at epoch 19 is 0.24798472225666046\n",
      "Elapsed time at start of epoch 20 is 87.16513419151306s\n",
      "Training accuracy at epoch 20 is 27.0\n",
      "Mean training loss at epoch 20 is 0.04437774270772934\n",
      "Validaton accuracy at epoch 20 is 0.7142857142857143\n",
      "Mean validation loss at epoch 20 is 0.26537907123565674\n",
      "Elapsed time at start of epoch 21 is 83.67144393920898s\n",
      "Training accuracy at epoch 21 is 27.0\n",
      "Mean training loss at epoch 21 is 0.04172690585255623\n",
      "Validaton accuracy at epoch 21 is 0.7142857142857143\n",
      "Mean validation loss at epoch 21 is 0.25297051668167114\n",
      "Elapsed time at start of epoch 22 is 79.57154893875122s\n",
      "Training accuracy at epoch 22 is 27.0\n",
      "Mean training loss at epoch 22 is 0.039843862131237986\n",
      "Validaton accuracy at epoch 22 is 0.7142857142857143\n",
      "Mean validation loss at epoch 22 is 0.2672800123691559\n",
      "Elapsed time at start of epoch 23 is 79.67796397209167s\n",
      "Training accuracy at epoch 23 is 27.0\n",
      "Mean training loss at epoch 23 is 0.03840056583285332\n",
      "Validaton accuracy at epoch 23 is 0.7142857142857143\n",
      "Mean validation loss at epoch 23 is 0.2855469286441803\n",
      "Elapsed time at start of epoch 24 is 79.63125801086426s\n",
      "Training accuracy at epoch 24 is 27.0\n",
      "Mean training loss at epoch 24 is 0.036438965052366254\n",
      "Validaton accuracy at epoch 24 is 0.7142857142857143\n",
      "Mean validation loss at epoch 24 is 0.28167101740837097\n",
      "Elapsed time at start of epoch 25 is 79.45635890960693s\n",
      "Training accuracy at epoch 25 is 27.0\n",
      "Mean training loss at epoch 25 is 0.033358809724450114\n",
      "Validaton accuracy at epoch 25 is 0.7142857142857143\n",
      "Mean validation loss at epoch 25 is 0.2817997932434082\n",
      "Elapsed time at start of epoch 26 is 79.5381121635437s\n",
      "Training accuracy at epoch 26 is 27.0\n",
      "Mean training loss at epoch 26 is 0.03347972184419632\n",
      "Validaton accuracy at epoch 26 is 0.7142857142857143\n",
      "Mean validation loss at epoch 26 is 0.28323081135749817\n",
      "Elapsed time at start of epoch 27 is 79.57343697547913s\n",
      "Training accuracy at epoch 27 is 27.0\n",
      "Mean training loss at epoch 27 is 0.031278128176927565\n",
      "Validaton accuracy at epoch 27 is 0.7142857142857143\n",
      "Mean validation loss at epoch 27 is 0.28493550419807434\n",
      "Elapsed time at start of epoch 28 is 79.51506018638611s\n",
      "Training accuracy at epoch 28 is 27.0\n",
      "Mean training loss at epoch 28 is 0.030268162861466406\n",
      "Validaton accuracy at epoch 28 is 0.7142857142857143\n",
      "Mean validation loss at epoch 28 is 0.2931724488735199\n",
      "Elapsed time at start of epoch 29 is 79.63841676712036s\n",
      "Training accuracy at epoch 29 is 27.0\n",
      "Mean training loss at epoch 29 is 0.02877967171370983\n",
      "Validaton accuracy at epoch 29 is 0.7142857142857143\n",
      "Mean validation loss at epoch 29 is 0.3104991018772125\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size=BATCH_SIZE\n",
    "device='cpu'\n",
    "learning_rate=0.00001\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, correct_bias=False)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "oldtime = time.time()\n",
    "\n",
    "for i  in range(epochs):\n",
    "    newtime = time.time()\n",
    "    delta = newtime - oldtime\n",
    "    oldtime = newtime\n",
    "    print(f'Elapsed time at start of epoch {i} is {delta}s')\n",
    "    accuracy, mean_loss = train(batch_size,train_dataloader, model, loss_fn, len(df_train), optimizer, device)\n",
    "    history['train_acc'].append(accuracy)\n",
    "    history['train_loss'].append(mean_loss)\n",
    "    print(f'Training accuracy at epoch {i} is {accuracy}')\n",
    "    print(f'Mean training loss at epoch {i} is {mean_loss}')\n",
    "    valAccuracy, mean_val_loss = validate(model, val_dataloader, loss_fn, len(df_val), device)\n",
    "    history['val_acc'].append(valAccuracy)\n",
    "    history['val_loss'].append(mean_val_loss)\n",
    "    print(f'Validaton accuracy at epoch {i} is {valAccuracy}')\n",
    "    print(f'Mean validation loss at epoch {i} is {mean_val_loss}')\n",
    "    \n",
    "    if valAccuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = valAccuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedaddc9",
   "metadata": {
    "id": "dedaddc9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef2212",
   "metadata": {
    "id": "07ef2212"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6dadb",
   "metadata": {
    "id": "bdc6dadb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bert_stance_detection_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
